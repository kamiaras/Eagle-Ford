{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e137fdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def generate_sensitivity_csvs(\n",
    "    run_folder: str,\n",
    "    fold: int,\n",
    "    test_csv: str,\n",
    "    sample_indices: list[int],\n",
    "    total_propellant_vals: list[float],\n",
    "    fluid_ratio_min: float = 0.4,\n",
    "    fluid_ratio_max: float = 10.0,\n",
    "    num_fluid_points: int = 10,\n",
    "    output_folder: str = \"sensitivity_csvs\"\n",
    "):\n",
    "    \"\"\"\n",
    "    For each total_propellant in total_propellant_vals, produce a CSV:\n",
    "      - Columns: the swept Total Fluid values\n",
    "      - Rows: each (sample_index, fluid_type) pair\n",
    "      - Cell: predicted Output 1 (first output) for that sample & fluid type\n",
    "    \"\"\"\n",
    "    # ─── Column headers ───────────────────────────────────────────────────────\n",
    "    output_cols       = [\"BOE_Prodoction_2 year cum\", \"BOE_Production_6mon cum\"]\n",
    "    gpi_col           = \"GPI (gross perforated interval ft)\"\n",
    "    prop_per_gpi_col  = \"Proppant.per.GPI..lb.ft.\"\n",
    "    fluid_per_gpi_col = \"Fluid.per.GPI..gal.ft.\"\n",
    "    total_prop_col    = \"Total.Proppant.Volume\"\n",
    "    total_fluid_col   = \"Total.Fluid\"\n",
    "    fluid_type_col    = \"Fluid.Type\"\n",
    "\n",
    "    # ─── Load hyperparams & norms ─────────────────────────────────────────────\n",
    "    run_id     = os.path.basename(os.path.normpath(run_folder))\n",
    "    with open(os.path.join(run_folder, f\"{run_id}_hyperparams.json\")) as f:\n",
    "        hp = json.load(f)\n",
    "    with open(os.path.join(run_folder, f\"{run_id}_norms.json\")) as f:\n",
    "        norms = json.load(f)\n",
    "    layer_dims, activations = hp[\"layer_dims\"], hp[\"activations\"]\n",
    "    y_mean = np.array(norms[\"y_mean\"], dtype=np.float32)\n",
    "    y_std  = np.array(norms[\"y_std\"],  dtype=np.float32)\n",
    "    x_mean = norms[\"x_mean\"]\n",
    "    x_std  = norms[\"x_std\"]\n",
    "\n",
    "    # ─── Load test data ───────────────────────────────────────────────────────\n",
    "    df = pd.read_csv(test_csv)\n",
    "\n",
    "    numeric_feats = list(x_mean.keys())\n",
    "    fluid_types   = sorted(df[fluid_type_col].unique())\n",
    "    dummy_feats   = [f\"{fluid_type_col}_{ft}\" for ft in fluid_types]\n",
    "\n",
    "    # ─── Define & load the trained MLP ────────────────────────────────────────\n",
    "    class MLPNet(nn.Module):\n",
    "        def __init__(self, in_dim, hidden_dims, activations, out_dim):\n",
    "            super().__init__()\n",
    "            layers, dims = [], [in_dim] + hidden_dims\n",
    "            for i, h in enumerate(hidden_dims):\n",
    "                layers.append(nn.Linear(dims[i], dims[i+1]))\n",
    "                act = activations[i].lower()\n",
    "                if   act=='relu':     layers.append(nn.ReLU())\n",
    "                elif act=='tanh':     layers.append(nn.Tanh())\n",
    "                elif act=='sigmoid':  layers.append(nn.Sigmoid())\n",
    "                elif act=='softplus': layers.append(nn.Softplus())\n",
    "                else: raise ValueError(f\"Unknown activation '{activations[i]}'\")\n",
    "            layers.append(nn.Linear(dims[-1], out_dim))\n",
    "            self.net = nn.Sequential(*layers)\n",
    "        def forward(self, x):\n",
    "            return self.net(x)\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = MLPNet(\n",
    "        in_dim      = len(numeric_feats) + len(dummy_feats),\n",
    "        hidden_dims = layer_dims,\n",
    "        activations = activations,\n",
    "        out_dim     = len(output_cols)\n",
    "    ).to(device)\n",
    "    model.load_state_dict(torch.load(\n",
    "        os.path.join(run_folder, f\"{run_id}_fold{fold}.pth\"),\n",
    "        map_location=device\n",
    "    ))\n",
    "    model.eval()\n",
    "\n",
    "    # ─── Ensure output directory exists ───────────────────────────────────────\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # ─── For each propellant value, build and save a CSV ─────────────────────\n",
    "    for prop_val in total_propellant_vals:\n",
    "        # generate a list of total fluid sweep values\n",
    "        fluid_vals = np.linspace(\n",
    "            prop_val * fluid_ratio_min,\n",
    "            prop_val * fluid_ratio_max,\n",
    "            num_fluid_points\n",
    "        ).tolist()\n",
    "\n",
    "        # prepare a mapping: (sample_index, fluid_type) -> list of preds\n",
    "        data = []\n",
    "        index = []\n",
    "\n",
    "        for sample_index in sample_indices:\n",
    "            sample = df.iloc[sample_index]\n",
    "            gpi = float(sample[gpi_col])\n",
    "\n",
    "            # baseline numeric features from sample\n",
    "            base_feats = {f: float(sample[f]) for f in numeric_feats}\n",
    "            # we'll overwrite dummies per fluid_type\n",
    "            for d in dummy_feats:\n",
    "                base_feats[d] = 0.0\n",
    "\n",
    "            for ft in fluid_types:\n",
    "                # one-hot encode this fluid type\n",
    "                for dft in dummy_feats:\n",
    "                    base_feats[dft] = 1.0 if dft == f\"{fluid_type_col}_{ft}\" else 0.0\n",
    "\n",
    "                # collect predictions over fluid_vals\n",
    "                preds = []\n",
    "                for fv in fluid_vals:\n",
    "                    base_feats[total_prop_col]  = prop_val\n",
    "                    base_feats[total_fluid_col] = fv\n",
    "                    base_feats[prop_per_gpi_col]  = prop_val / gpi\n",
    "                    base_feats[fluid_per_gpi_col] = fv    / gpi\n",
    "\n",
    "                    # build & normalize input vector\n",
    "                    x_vec = [(base_feats[f] - x_mean[f]) / x_std[f] for f in numeric_feats]\n",
    "                    x_vec += [base_feats[d] for d in dummy_feats]\n",
    "\n",
    "                    X_in = torch.tensor([x_vec], dtype=torch.float32).to(device)\n",
    "                    with torch.no_grad():\n",
    "                        yp_n = model(X_in).cpu().numpy().flatten()\n",
    "                    # only first output\n",
    "                    yp = yp_n[0] * y_std[0] + y_mean[0]\n",
    "                    preds.append(float(yp))\n",
    "\n",
    "                data.append(preds)\n",
    "                index.append((sample_index, ft))\n",
    "\n",
    "        # build DataFrame\n",
    "        df_out = pd.DataFrame(\n",
    "            data,\n",
    "            index=pd.MultiIndex.from_tuples(index, names=[\"sample_index\",\"fluid_type\"]),\n",
    "            columns=[f\"{fv:.2f}\" for fv in fluid_vals]\n",
    "        )\n",
    "\n",
    "        # save to CSV\n",
    "        out_path = os.path.join(output_folder, f\"prop_{prop_val:.0f}.csv\")\n",
    "        df_out.to_csv(out_path)\n",
    "        print(f\"Saved {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ebdeb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sensitivity_csvs/prop_300000.csv\n",
      "Saved sensitivity_csvs/prop_2300000.csv\n",
      "Saved sensitivity_csvs/prop_4300000.csv\n",
      "Saved sensitivity_csvs/prop_6300000.csv\n",
      "Saved sensitivity_csvs/prop_8300000.csv\n",
      "Saved sensitivity_csvs/prop_10300000.csv\n",
      "Saved sensitivity_csvs/prop_12300000.csv\n",
      "Saved sensitivity_csvs/prop_14300000.csv\n",
      "Saved sensitivity_csvs/prop_16300000.csv\n",
      "Saved sensitivity_csvs/prop_18300000.csv\n",
      "Saved sensitivity_csvs/prop_20300000.csv\n"
     ]
    }
   ],
   "source": [
    "generate_sensitivity_csvs(\n",
    "    run_folder=\"/home/kamiar/chevron/Eagle-Ford/First/606d04aa\",\n",
    "    fold=6,\n",
    "    test_csv=\"/home/kamiar/chevron/Eagle-Ford/First/data/Eagle Ford Data(Eagle Ford)_test.csv\",\n",
    "    sample_indices=list(range(127)),                 # example list of sample indices\n",
    "    total_propellant_vals=np.linspace(300_000, 20_300_000, num=11).tolist(),          # propellant sweep\n",
    "    fluid_ratio_min=0.4,\n",
    "    fluid_ratio_max=2.0,\n",
    "    num_fluid_points=15,\n",
    "    output_folder=\"sensitivity_csvs\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
